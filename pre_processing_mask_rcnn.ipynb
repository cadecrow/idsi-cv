{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import crop_image as ci\n",
    "from preprocessing.load_file import check_num_images\n",
    "import csv\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import random\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# split into train and test set\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from Mask_RCNN.mrcnn.utils import Dataset\n",
    "from Mask_RCNN.mrcnn.visualize import display_instances\n",
    "from Mask_RCNN.mrcnn.utils import extract_bboxes\n",
    "from Mask_RCNN.mrcnn.config import Config\n",
    "from Mask_RCNN.mrcnn.model import MaskRCNN\n",
    "from Mask_RCNN.mrcnn.utils import compute_ap\n",
    "from Mask_RCNN.mrcnn.model import load_image_gt\n",
    "from Mask_RCNN.mrcnn.model import mold_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_name = \"../full_data_train.csv\"\n",
    "path_training = \"../train/sampled_images/\" # path from current folder to training images\n",
    "#path_testing = \"data/test/\" # path from current folder to testing images\n",
    "#path_testing = \"train/images/\" # path from current folder to testing images\n",
    "\n",
    "percent_training = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class that defines and loads the buildings dataset\n",
    "class BuildingsDataset(Dataset):\n",
    "    # load the dataset definitions\n",
    "    def load_dataset(self, path, data_file_name, percent_training, is_train=True):\n",
    "        # define one class\n",
    "        self.add_class(\"dataset\", 1, \"building\")\n",
    "        # find all images\n",
    "        count = 0\n",
    "        m_training = round(len(listdir(path)) * percent_training)\n",
    "        for filename in listdir(path):\n",
    "            if(filename[-3:] != \"png\"):\n",
    "                continue\n",
    "            # extract image id\n",
    "            image_id = filename[:-4]\n",
    "            # skip all images after m_training if we are building the train set\n",
    "            if is_train and count >= m_training:\n",
    "                count += 1\n",
    "                continue\n",
    "            # skip all images before m_training if we are building the test/val set\n",
    "            if not is_train and count < m_training:\n",
    "                count += 1\n",
    "                continue\n",
    "            count += 1 \n",
    "            img_path = path + filename\n",
    "            # add to dataset\n",
    "            self.add_image('dataset', image_id=image_id, path=img_path, filename=filename, data_file_name=data_file_name)\n",
    "            \n",
    "    # Load and process the images for the mini-batch\n",
    "    def extract_boxes(self, filename, data_file_name):\n",
    "        boxes = []\n",
    "        ### Find the rows associated with the file\n",
    "        with open(data_file_name) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            for row in csv_reader:\n",
    "                if (row[0] == \"\"):\n",
    "                    continue\n",
    "                if (row[17] == filename):\n",
    "                    xy = row[22]\n",
    "                    points = ci.process_xy(xy)\n",
    "                    (xmin, xmax, ymin, ymax) = ci.get_corners(points)\n",
    "                    coordinates = [xmin, ymin, xmax, ymax]\n",
    "                    boxes.append(coordinates)\n",
    "        return (boxes, 1024, 1024)\n",
    "                \n",
    "    # load the masks for an image\n",
    "    def load_mask(self, image_id):\n",
    "        # get details of image\n",
    "        info = self.image_info[image_id]\n",
    "        filename = info['filename']\n",
    "        data_file_name = info['data_file_name']\n",
    "        boxes, w, h = self.extract_boxes(filename, data_file_name)\n",
    "        # create one array for all masks, each on a different channel\n",
    "        masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "        # create masks\n",
    "        class_ids = []\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i]\n",
    "            row_s, row_e = box[1], box[3]\n",
    "            col_s, col_e = box[0], box[2]\n",
    "            masks[row_s:row_e, col_s:col_e, i] = 1\n",
    "            class_ids.append(self.class_names.index('building'))\n",
    "        return masks, asarray(class_ids, dtype='int32')\n",
    " \n",
    "    # load an image reference\n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 97\n",
      "Test: 23\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "train_set = BuildingsDataset()\n",
    "train_set.load_dataset(path_training, data_file_name, percent_training, True)\n",
    "train_set.prepare()\n",
    "\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "\n",
    "# test/val set\n",
    "test_set = BuildingsDataset()\n",
    "test_set.load_dataset(path_training, data_file_name, percent_training, False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing BuildingsDataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image\n",
    "image_id = 1\n",
    "image = test_set.load_image(image_id)\n",
    "print(image.shape)\n",
    "# load image mask\n",
    "mask, class_ids = test_set.load_mask(image_id)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot image\n",
    "pyplot.imshow(image)\n",
    "# plot mask\n",
    "pyplot.imshow(mask[:, :, 1], cmap='gray', alpha=0.5)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract bounding boxes from the masks\n",
    "bbox = extract_bboxes(mask)\n",
    "# display image with masks and bounding boxes\n",
    "display_instances(image, bbox, mask, class_ids, train_set.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a configuration for the model\n",
    "class BuildingConfig(Config):\n",
    "\t# Give the configuration a recognizable name\n",
    "\tNAME = \"building_cfg\"\n",
    "\t# Number of classes (background + building)\n",
    "\tNUM_CLASSES = 1 + 1\n",
    "\t# Number of training steps per epoch\n",
    "\tSTEPS_PER_EPOCH = len(train_set.image_ids)\n",
    " \n",
    "# prepare config\n",
    "config = BuildingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
    "\n",
    "model.keras_model.metrics_tensors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights (mscoco) and exclude the output layers\n",
    "model.load_weights('../mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train weights (output layers or 'heads')\n",
    "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=5, layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision refers to the percentage of the correctly predicted bounding boxes (IoU > 0.5) out of all bounding boxes predicted. Recall is the percentage of the correctly predicted bounding boxes (IoU > 0.5) out of all objects in the photo.\n",
    "\n",
    "As we make more predictions, the recall percentage will increase, but precision will drop or become erratic as we start making false positive predictions. The recall (x) can be plotted against the precision (y) for each number of predictions to create a curve or line. We can maximize the value of each point on this line and calculate the average value of the precision or AP for each value of recall.\n",
    "\n",
    "The average or mean of the average precision (AP) across all of the images in a dataset is called the mean average precision, or mAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the prediction configuration\n",
    "class PredictionConfig(Config):\n",
    "\t# define the name of the configuration\n",
    "\tNAME = \"building_cfg\"\n",
    "\t# number of classes (background + kangaroo)\n",
    "\tNUM_CLASSES = 1 + 1\n",
    "\t# simplify GPU config\n",
    "\tGPU_COUNT = 1\n",
    "\tIMAGES_PER_GPU = 1\n",
    "    \n",
    "# calculate the mAP for a model on a given dataset\n",
    "def evaluate_model(dataset, model, cfg):\n",
    "    APs = list()\n",
    "    for image_id in dataset.image_ids:\n",
    "        # load image, bounding boxes and masks for the image id\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
    "        # convert pixel values (e.g. center)\n",
    "        scaled_image = mold_image(image, cfg)\n",
    "        # convert image into one sample\n",
    "        sample = expand_dims(scaled_image, 0)\n",
    "        # make prediction\n",
    "        yhat = model.detect(sample, verbose=0)\n",
    "        # extract results for first sample\n",
    "        r = yhat[0]\n",
    "        if(gt_bbox.shape[0] == 0):\n",
    "            continue\n",
    "        # calculate statistics, including AP\n",
    "        AP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "        # store\n",
    "        APs.append(AP)\n",
    "    # calculate the mean AP across all images\n",
    "    mAP = mean(APs)\n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/abuzarroyesh/Desktop/Classes/deep_learning/CS230/Mask_RCNN/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/abuzarroyesh/Desktop/Classes/deep_learning/CS230/Mask_RCNN/mrcnn/model.py:399: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/abuzarroyesh/Desktop/Classes/deep_learning/CS230/Mask_RCNN/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /Users/abuzarroyesh/Desktop/Classes/deep_learning/CS230/Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/abuzarroyesh/Desktop/Classes/deep_learning/CS230/Mask_RCNN/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/abuzarroyesh/Desktop/Classes/deep_learning/CS230/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "# create config\n",
    "cfg = PredictionConfig()\n",
    "# define the model\n",
    "model = MaskRCNN(mode='inference', model_dir='./', config=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weights from the model that has the best accuracy\n",
    "model.load_weights('building_cfg20200530T2056/mask_rcnn_building_cfg_0005.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Test mAP: 0.220\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on test dataset\n",
    "test_mAP = evaluate_model(test_set, model, cfg)\n",
    "print(\"Test mAP: %.3f\" % test_mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
